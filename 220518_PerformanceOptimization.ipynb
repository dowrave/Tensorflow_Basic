{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220518_PerformanceOptimization.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN21ZhLbvmVHsKBrvwxjgd2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dowrave/Tensorflow_Basic/blob/main/220518_PerformanceOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJIVbWWfw3hi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 지연 시간이 중간중간 들어가 있는 것만 포인트"
      ],
      "metadata": {
        "id": "cxqFupIyyXIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 3개의 샘플 생성 + 1번째 항목이 파일 열기 전 휴면 + 읽기 시뮬레이션 항목 생성 전에 휴면\n",
        "class ArtificialDataset(tf.data.Dataset):\n",
        "  def _generator(num_samples):\n",
        "    time.sleep(.03)\n",
        "\n",
        "    for sample_idx in range(num_samples):\n",
        "      time.sleep(.015)\n",
        "      yield (sample_idx, )\n",
        "\n",
        "  def __new__(cls, num_samples = 3):\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        cls._generator,\n",
        "        output_types = tf.dtypes.int64,\n",
        "        output_shapes = (1, ),\n",
        "        args = (num_samples, )\n",
        "    )"
      ],
      "metadata": {
        "id": "EMfCFrDQxe9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련 루프 : 데이터셋 반복 시간을 측정하는 더미 훈련 루프. 훈련 시간이 시뮬레이션 됨"
      ],
      "metadata": {
        "id": "wRqE023rycw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark(dataset, num_epochs = 2):\n",
        "  start_time = time.perf_counter()\n",
        "  for epoch_num in range(num_epochs):\n",
        "    for sample in dataset:\n",
        "      time.sleep(.01)\n",
        "  tf.print(\"실행 시간 : \", time.perf_counter() - start_time)"
      ],
      "metadata": {
        "id": "UNkEDVYqx5M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 최적화"
      ],
      "metadata": {
        "id": "ZK2994jGyi7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 그냥 실행\n",
        "benchmark(ArtificialDataset()) # 0.29 ~ 0.30"
      ],
      "metadata": {
        "id": "2bN6h4C8ygzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위 실행 시간은 파일 열기 -> 읽기 -> 훈련하기 -> 읽기 -> 훈련하기 각각의 과정이 1개씩만 진행됨.\n",
        "  - 즉 하나가 진행되면 나머지 2개는 유휴 상태임\n",
        "- 이를 개선하는 방법이 아래와 같음"
      ],
      "metadata": {
        "id": "-HGrhLgOyoHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 가져오기(Prefetching)\n",
        "- 전처리 ~ 훈련 스텝 실행을 오버랩함. 모델이 s스텝을 실행하는 동안 입력 파이프라인은 s+1 스텝의 데이터를 읽음.\n",
        "- `tf.data.Dataset.prefetch` 변환이 제공되며 이는 데이터 소비 시간과 생성 시간 간의 의존성을 줄일 수 있음. \n",
        "  - 백그라운드 스레드와 내부 버퍼를 사용하여 요청된 시간 전에 입력 데이터셋에서 요소를 가져옴.\n",
        "  - 요소 수는 배치 수와 같거나 커야 함\n",
        "  - 이를 수동으로 조정하거나 `tf.data.experimental.AUTOTUNE`으로 설정하면 `tf.data` 런타임이 실행 시 동적으로 값을 조정함\n"
      ],
      "metadata": {
        "id": "qUvC_P7-y32V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark(\n",
        "    ArtificialDataset().prefetch(tf.data.experimental.AUTOTUNE)\n",
        ") # 0.23"
      ],
      "metadata": {
        "id": "QPDyxHsvygn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 추출 병렬화\n",
        "- 실제 환경에서는 입력 데이터를 원격으로(GCS, HDFS) 저장할 수 있음.\n",
        "- 로컬에서 읽는 데이터셋 파이프라인은 로컬, 원격 저장소의 차이 때문에 원격으로 데이터를 읽을 때 입출력에 병목이 발생할 수 있음\n",
        "  - 1번째 바이트 : 원격 저장소에서 1번째 바이트를 읽는 건 로컬보다 훨씬 오래 걸림\n",
        "  - 읽기 처리량 : 원격 저장소는 큰 총 대역폭을 가지나 한 파일을 읽을 땐 일부만 사용 가능함\n",
        "  - 바이트들이 메모리로 읽히면 데이터를 역직렬화하고 해독할 필요가 있을 수 있다.\n",
        "    - 이는 추가 계산이 필요함.\n",
        "  \n",
        "- 다양한 데이터 추출 오버헤드 영향을 줄이고자, `tf.data.Dataset.interleave` 변환이 있다. 이는 데이터 추출 단계를 병렬화하는데 사용할 수 있음.\n",
        "  - 중첩할 데이터셋은 `cycle_length`로 지정\n",
        "  - 병렬처리 수준은 `num_parallel_calls`로 지정.\n",
        "- `prefetch`, `map` 변환과 비슷하게 `interleave` 변환은 `tf.data.experimental.AUTOTUNE`을 지원한다."
      ],
      "metadata": {
        "id": "QOu4nIMfz0d1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 순차적\n",
        "benchmark(tf.data.Dataset.range(2).interleave(ArtificalDataset)) # 0.29s"
      ],
      "metadata": {
        "id": "wj2MFXPdzarl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위 코드는 실질적인 성능의 향상은 없지만, 파일을 여는 과정을 분리함(원래는 전체를 열고 시작했다면, 여기서는 1/2 열고 일부를 읽고 훈련하고 1/2 열고 일부를 읽고 훈련하고 를 반복함"
      ],
      "metadata": {
        "id": "2lqIjV4X0yT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 병렬 인터리브\n",
        "benchmark(tf.data.Dataset.range(2).interleave(ArtificialDataset, num_parallel_calls = tf.data.experimental.AUTOTUNE)) # 0.21s"
      ],
      "metadata": {
        "id": "5kqUBgZr0tpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 왜 처음 실행할 때는 느렸다가 갈수록 빨라지는지 모르겠지만 얘도 0.2초대까지 빨라짐"
      ],
      "metadata": {
        "id": "YUEyIbGg1PS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 변환 병렬화\n",
        "- 입력 요소들은 전처리가 필요할 수 있다. 이를 위해 `tf.data.Dataset.map` 변환이 있고 이는 사용자 정의 함수를 입력 데이터셋의 각 요소에 적용함.\n",
        "  - 입력 요소들이 독립적이기 때문에 여러 CPU 코어에서 병렬로 실행될 수 있다.\n",
        "- 이를 위해 `map` 변환도 `num_parallel_calls` 인수를 지원한다. \n",
        "- 얘도 `tf.data.experimental.AUTOTUNE`을 지원함."
      ],
      "metadata": {
        "id": "LbAw8Gc51WfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mapped_function(s):\n",
        "  tf.py_function(lambda: time.sleep(0.03), [], ())\n",
        "  return s"
      ],
      "metadata": {
        "id": "pg8hnQTI1LZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 순차적\n",
        "benchmark(ArtificialDataset().map(mapped_function)) # 0.47 ~ 0.65s\n",
        "\n",
        "# 병렬\n",
        "benchmark(ArtificialDataset().map(mapped_function, num_parallel_calls = tf.data.experimental.AUTOTUNE)) # 0.33s"
      ],
      "metadata": {
        "id": "HkVewYsc1xKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 캐시하기\n",
        "`tf.data.Dataset.cache` 변환은 데이터셋을 메모리, 로컬 저장소에 캐시할 수 있다. 각 에포크 동안 실행되는 일부 작업이 저장됨."
      ],
      "metadata": {
        "id": "oEmF6nRZ2M1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark(ArtificialDataset().map(\n",
        "    mapped_function # 캐시 전 시간이많이 걸리는 작업\n",
        "    ).cache(), 5)"
      ],
      "metadata": {
        "id": "UMDppW6V1z1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- cache 이전의 변환은 1번째 에포크 동안에만 실행된다. 다음 에포크에는 cache 변환에 의해 캐시된 데이터를 재사용한다."
      ],
      "metadata": {
        "id": "yh4HpMsy2joF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 매핑 벡터화\n",
        "- `map` 변환으로 전달된 사용자 정의 함수를 호출 시 사용자 정의 함수의 스케줄링 및 실행에 관련된 오버헤드가 있다.\n",
        "- 사용자 정의 함수를 벡터화(한 번에 여러 입력에 작동하도록)하고 맵을 변환하기 전에 배치 변환을 하는 것이 좋다.\n",
        "- <b> 무슨 얘기다? 데이터셋을 벡터화(batch로 만듦)하고 map 함수를 가해라~ </b>"
      ],
      "metadata": {
        "id": "YmYI3vhr2-0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fast_dataset = tf.data.Dataset.range(1000)\n",
        "\n",
        "def fast_benchmark(dataset, num_epochs = 2):\n",
        "  start_time = time.perf_counter()\n",
        "  for _ in tf.data.Dataset.range(num_epochs):\n",
        "    for _ in dataset:\n",
        "      pass\n",
        "  tf.print(\"실행 시간 : \", time.perf_counter() - start_time)\n",
        "\n",
        "def increment(x):\n",
        "  return x + 1"
      ],
      "metadata": {
        "id": "iLK9_YoD2eM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스칼라 매핑\n",
        "fast_benchmark(fast_dataset.map(increment).batch(256)) # 0.08s : 매핑이 여러 번에 걸쳐 일어남"
      ],
      "metadata": {
        "id": "moUm60wu3X0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터 매핑\n",
        "fast_benchmark(fast_dataset.batch(256).map(increment)) # 0.03s : 매핑은 딱 1번만 진행됨"
      ],
      "metadata": {
        "id": "CPhGhkla3b8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 메모리 사용량 줄이기\n",
        "- `interleave`, `prefetch`, `shuffle` 등의 많은 변환은 요소들의 내부 버퍼를 유지한다. 대충 메모리 사용량이 낮아지는 순서를 고르라는 얘기"
      ],
      "metadata": {
        "id": "EBwRvNTm36gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 부분계산 캐싱 : 데이터가 너무 큰 경우를 제외하면 map 변환 후 데이터셋을 캐시하는 것이 좋다.\n",
        "dataset.map(time_consuming_mapping).cache().map(memory.consuming_mapping)"
      ],
      "metadata": {
        "id": "gDqTXmqt3lrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예제\n",
        "- `prefetch 변환` : 프로듀서, 컨슈머의 작업 오버랩\n",
        "- `interleave 변환` : 데이터 읽기 변환 병렬화\n",
        "- `num_parallel_calls` : map 변환 병렬 처리\n",
        "- `cache 변환` : 데이터가 메모리에 저장될 수 있다면 1번째 에포크 동안 데이터를 메모리에 캐시\n",
        "- `map` 변환 : 사용자 정의 함수 벡터화 (이건 batch 먼저 지정하라는 뜻)\n",
        " `interleave`, `prefetch`, `shuffle` 변환 -> 메모리 사용 줄여라"
      ],
      "metadata": {
        "id": "RHo6atNj4egf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그림 재현\n",
        "- 이 안내서에 나온 이미지를 그리는 데 사용된 코드임\n",
        "- 여기는 그냥 복붙함. 따라친다고 이해될 부분은 아님"
      ],
      "metadata": {
        "id": "BLXJFiky4wyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "ctl6-s5N4P2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 \n",
        "- 각 단계에서 소요된 시간을 리턴하는 데이터셋"
      ],
      "metadata": {
        "id": "cFI-4VVa5Aqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeMeasuredDataset(tf.data.Dataset):\n",
        "    # 출력: (steps, timings, counters)\n",
        "    OUTPUT_TYPES = (tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32)\n",
        "    OUTPUT_SHAPES = ((2, 1), (2, 2), (2, 3))\n",
        "\n",
        "    _INSTANCES_COUNTER = itertools.count()  # 생성된 데이터셋 수\n",
        "    _EPOCHS_COUNTER = defaultdict(itertools.count)  # 각 데이터를 수행한 에포크 수\n",
        "\n",
        "    def _generator(instance_idx, num_samples):\n",
        "        epoch_idx = next(TimeMeasuredDataset._EPOCHS_COUNTER[instance_idx])\n",
        "\n",
        "        # 파일 열기\n",
        "        open_enter = time.perf_counter()\n",
        "        time.sleep(0.03)\n",
        "        open_elapsed = time.perf_counter() - open_enter\n",
        "\n",
        "        for sample_idx in range(num_samples):\n",
        "            # 파일에서 데이터(줄, 기록) 읽어오기\n",
        "            read_enter = time.perf_counter()\n",
        "            time.sleep(0.015)\n",
        "            read_elapsed = time.perf_counter() - read_enter\n",
        "\n",
        "            yield (\n",
        "                [(\"Open\",), (\"Read\",)],\n",
        "                [(open_enter, open_elapsed), (read_enter, read_elapsed)],\n",
        "                [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, sample_idx)]\n",
        "            )\n",
        "            open_enter, open_elapsed = -1., -1.  # 음수는 필터링됨\n",
        "\n",
        "\n",
        "    def __new__(cls, num_samples=3):\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_types=cls.OUTPUT_TYPES,\n",
        "            output_shapes=cls.OUTPUT_SHAPES,\n",
        "            args=(next(cls._INSTANCES_COUNTER), num_samples)\n",
        "        )"
      ],
      "metadata": {
        "id": "GvLdxj8p4-AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 반복 루프"
      ],
      "metadata": {
        "id": "v0Ajj5fv6j9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def timelined_benchmark(dataset, num_epochs=2):\n",
        "    # 누산기 초기화\n",
        "    steps_acc = tf.zeros([0, 1], dtype=tf.dtypes.string)\n",
        "    times_acc = tf.zeros([0, 2], dtype=tf.dtypes.float32)\n",
        "    values_acc = tf.zeros([0, 3], dtype=tf.dtypes.int32)\n",
        "\n",
        "    start_time = time.perf_counter()\n",
        "    for epoch_num in range(num_epochs):\n",
        "        epoch_enter = time.perf_counter()\n",
        "        for (steps, times, values) in dataset:\n",
        "            # 데이터셋 준비 정보 기록하기\n",
        "            steps_acc = tf.concat((steps_acc, steps), axis=0)\n",
        "            times_acc = tf.concat((times_acc, times), axis=0)\n",
        "            values_acc = tf.concat((values_acc, values), axis=0)\n",
        "\n",
        "            # 훈련 시간 시뮬레이션\n",
        "            train_enter = time.perf_counter()\n",
        "            time.sleep(0.01)\n",
        "            train_elapsed = time.perf_counter() - train_enter\n",
        "\n",
        "            # 훈련 정보 기록하기\n",
        "            steps_acc = tf.concat((steps_acc, [[\"Train\"]]), axis=0)\n",
        "            times_acc = tf.concat((times_acc, [(train_enter, train_elapsed)]), axis=0)\n",
        "            values_acc = tf.concat((values_acc, [values[-1]]), axis=0)\n",
        "\n",
        "        epoch_elapsed = time.perf_counter() - epoch_enter\n",
        "        # 에포크 정보 기록하기\n",
        "        steps_acc = tf.concat((steps_acc, [[\"Epoch\"]]), axis=0)\n",
        "        times_acc = tf.concat((times_acc, [(epoch_enter, epoch_elapsed)]), axis=0)\n",
        "        values_acc = tf.concat((values_acc, [[-1, epoch_num, -1]]), axis=0)\n",
        "        time.sleep(0.001)\n",
        "\n",
        "    tf.print(\"실행 시간:\", time.perf_counter() - start_time)\n",
        "    return {\"steps\": steps_acc, \"times\": times_acc, \"values\": values_acc}"
      ],
      "metadata": {
        "id": "1EItMbKb6DrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_timeline(timeline, title, width=0.5, annotate=False, save=False):\n",
        "    # 타임라인에서 유효하지 않은 항목(음수 또는 빈 스텝) 제거\n",
        "    invalid_mask = np.logical_and(timeline['times'] > 0, timeline['steps'] != b'')[:,0]\n",
        "    steps = timeline['steps'][invalid_mask].numpy()\n",
        "    times = timeline['times'][invalid_mask].numpy()\n",
        "    values = timeline['values'][invalid_mask].numpy()\n",
        "\n",
        "    # 처음 발견될 때 순서대로 다른 스텝을 가져옵니다.\n",
        "    step_ids, indices = np.stack(np.unique(steps, return_index=True))\n",
        "    step_ids = step_ids[np.argsort(indices)]\n",
        "\n",
        "    # 시작 시간을 0으로 하고 최대 시간 값을 계산하십시오.\n",
        "    min_time = times[:,0].min()\n",
        "    times[:,0] = (times[:,0] - min_time)\n",
        "    end = max(width, (times[:,0]+times[:,1]).max() + 0.01)\n",
        "\n",
        "    cmap = mpl.cm.get_cmap(\"plasma\")\n",
        "    plt.close()\n",
        "    fig, axs = plt.subplots(len(step_ids), sharex=True, gridspec_kw={'hspace': 0})\n",
        "    fig.suptitle(title)\n",
        "    fig.set_size_inches(17.0, len(step_ids))\n",
        "    plt.xlim(-0.01, end)\n",
        "\n",
        "    for i, step in enumerate(step_ids):\n",
        "        step_name = step.decode()\n",
        "        ax = axs[i]\n",
        "        ax.set_ylabel(step_name)\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_yticks([])\n",
        "        ax.set_xlabel(\"time (s)\")\n",
        "        ax.set_xticklabels([])\n",
        "        ax.grid(which=\"both\", axis=\"x\", color=\"k\", linestyle=\":\")\n",
        "\n",
        "        # 주어진 단계에 대한 타이밍과 주석 얻기\n",
        "        entries_mask = np.squeeze(steps==step)\n",
        "        serie = np.unique(times[entries_mask], axis=0)\n",
        "        annotations = values[entries_mask]\n",
        "\n",
        "        ax.broken_barh(serie, (0, 1), color=cmap(i / len(step_ids)), linewidth=1, alpha=0.66)\n",
        "        if annotate:\n",
        "            for j, (start, width) in enumerate(serie):\n",
        "                annotation = \"\\n\".join([f\"{l}: {v}\" for l,v in zip((\"i\", \"e\", \"s\"), annotations[j])])\n",
        "                ax.text(start + 0.001 + (0.001 * (j % 2)), 0.55 - (0.1 * (j % 2)), annotation,\n",
        "                        horizontalalignment='left', verticalalignment='center')\n",
        "    if save:\n",
        "        plt.savefig(title.lower().translate(str.maketrans(\" \", \"_\")) + \".svg\")"
      ],
      "metadata": {
        "id": "y1x2RDId7cos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 즉시 실행에서 매핑된 함수라면, 그래프로 만들어준다.\n",
        "\n",
        "def map_decorator(func):\n",
        "    def wrapper(steps, times, values):\n",
        "        # 자동 그래프가 메서드를 컴파일하지 못하도록 tf.py_function을 사용\n",
        "        return tf.py_function(\n",
        "            func,\n",
        "            inp=(steps, times, values),\n",
        "            Tout=(steps.dtype, times.dtype, values.dtype)\n",
        "        )\n",
        "    return wrapper"
      ],
      "metadata": {
        "id": "uaROzB-d7eEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_batch_map_num_items = 50\n",
        "\n",
        "def dataset_generator_fun(*args):\n",
        "    return TimeMeasuredDataset(num_samples=_batch_map_num_items)"
      ],
      "metadata": {
        "id": "GU_EFrXw7mkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그냥 - 최적화 X\n",
        "@map_decorator\n",
        "def naive_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.001)  # 시간 소비 스텝\n",
        "    time.sleep(0.0001)  # 메모리 소비 스텝\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    return (\n",
        "        tf.concat((steps, [[\"Map\"]]), axis=0),\n",
        "        tf.concat((times, [[map_enter, map_elapsed]]), axis=0),\n",
        "        tf.concat((values, [values[-1]]), axis=0)\n",
        "    )\n",
        "\n",
        "naive_timeline = timelined_benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .flat_map(dataset_generator_fun)\n",
        "    .map(naive_map)\n",
        "    .batch(_batch_map_num_items, drop_remainder=True)\n",
        "    .unbatch(),\n",
        "    5\n",
        ")"
      ],
      "metadata": {
        "id": "Y23jMQmN7m7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@map_decorator\n",
        "def time_consumming_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.001 * values.shape[0])  # 시간 소비 스텝\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    return (\n",
        "        tf.concat((steps, tf.tile([[[\"1st map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
        "    )\n",
        "\n",
        "\n",
        "@map_decorator\n",
        "def memory_consumming_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.0001 * values.shape[0])  # 메모리 소비 스텝\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    # 배치 차원을 다루는 데 tf.tile 사용\n",
        "    return (\n",
        "        tf.concat((steps, tf.tile([[[\"2nd map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
        "    )\n",
        "\n",
        "\n",
        "optimized_timeline = timelined_benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(  # 데이터 읽기 병렬화\n",
        "        dataset_generator_fun,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .batch(  # 매핑된 함수 벡터화\n",
        "        _batch_map_num_items,\n",
        "        drop_remainder=True)\n",
        "    .map(  # 맵 변환 병렬화\n",
        "        time_consumming_map,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .cache()  # 데이터 캐시\n",
        "    .map(  # 메모리 사용량 줄이기\n",
        "        memory_consumming_map,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .prefetch(  # 프로듀서와 컨슈머 작업 오버랩\n",
        "        tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .unbatch(),\n",
        "    5\n",
        ")"
      ],
      "metadata": {
        "id": "Om8NKUSp70wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8jsKt6BA7qW5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}