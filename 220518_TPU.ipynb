{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220518_TPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhPaZZ+GBQBqs39tynANQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dowrave/Tensorflow_Basic/blob/main/220518_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qAEn_6fmPONA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "q_k87a1PPqJI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TPU 초기화\n",
        "- TPU는 사용자의 파이썬 프로그램을 실행하는 로컬 프로세스와 다른 Cloud TPU 작업자이다.\n",
        "- 즉 원격 클러스터에 연결하고 TPU를 초기화하려면 일부 초기화 작업을 수행해야 한다.\n",
        "- `tf.distribute.cluster_resolver.TPUClusterResolver`에 대한 `tpu` 인수는 전용 특수 주소다. \n",
        "  - 코랩과 같이 `Google Compute Engine(GCE)`에서 실행한다면 Cloud TPU의 이름을 전달한다.\n",
        "  - TPU 초기화 코드는 프로그램 시작 부분에 있어야 한다.\n",
        "\n",
        "* 코랩에서 TPU를 할당하지 못하는 경우가 있는데, 여러 번 반복하면 연결됨"
      ],
      "metadata": {
        "id": "pzwfIL2iPuYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TPU 초기화 작업 : 이것만 따로 저장해놓고 써도 될듯\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='') # 코랩에서 그냥 이대로 실행됩니다\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices : \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXybnES4Ptxy",
        "outputId": "eadb0496-84f1-484e-e6bb-b3fa9f95a65f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.2.81.138:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.2.81.138:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices :  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 수동 장치 배치\n",
        "- TPU 초기화 후 수동 장치 배치를 사용, 단일 TPU 장치에 계산을 배치할 수 있다."
      ],
      "metadata": {
        "id": "vN5fAmX3Q5LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용 방식은 동일함\n",
        "a = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "b = tf.constant([[1., 2.], [3., 4.], [5., 6.]])\n",
        "\n",
        "with tf.device('/TPU:0'):\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(\"c device : \", c.device)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scOYABkBQtMc",
        "outputId": "67b587bb-99a9-4fb2-e892-dbd0cc0c4114"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c device :  /job:worker/replica:0/task:0/device:TPU:0\n",
            "tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 유통 전략 : `tf.distribute.TPUStrategy`\n",
        "- 데이터 병렬 방식으로 여러 TPU에서 모델이 실행됨\n",
        "- 이를 위해 쓰이는 게 전략임"
      ],
      "metadata": {
        "id": "HnFuVx-HRMEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "zsddas7ERKJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 TPU 코어에서 실행시키려면 strategy.run API에 전달함\n",
        "@tf.function\n",
        "def matmul_fn(x, y):\n",
        "  z = tf.matmul(x, y)\n",
        "  return z\n",
        "\n",
        "z = strategy.run(matmul_fn, args=(a,b))\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e369me_RXFA",
        "outputId": "03a0b1a8-f2ba-49d7-a9d8-64460ab532d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PerReplica:{\n",
            "  0: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  1: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  2: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  3: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  4: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  5: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  6: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  7: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TPU를 이용한 분류(예제)\n",
        "- `tf.distribute.TPUStrategy`를 사용해 Cloud TPU에서 케라스 모델을 학습시킬 수 있다."
      ],
      "metadata": {
        "id": "hCQKhOyCRkRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 케라스 모델 정의\n",
        "def create_model():\n",
        "  return tf.keras.Sequential(\n",
        "      [tf.keras.layers.Conv2D(256, 3, activation = 'relu', input_shape = (28, 28, 1)),\n",
        "       tf.keras.layers.Conv2D(256, 3, activation = 'relu',),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "       tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "       tf.keras.layers.Dense(10)\n",
        "      ])"
      ],
      "metadata": {
        "id": "M1vLNZPKRfEE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 로드\n",
        "`tf.data.Dataset` API의 효율적인 사용은 매우 중요함\n",
        "- 대부분의 실험에서 데이터세트에서 읽은 모든 데이터 파일을 GCS 버킷에 저장해야 함\n",
        "  - 그리고 데이터를 `TFRecord` 형식으로 변환하고, `tf.data.TFRecordDataset`을 사용하여 읽는 방법이 좋다. `TFRecord, tf.Example 자습서`가 따로 있음.\n",
        "-`tf.data.Dataset.cache`로 작은 데이터 세트를 메모리에 로드하는 것도 가능함."
      ],
      "metadata": {
        "id": "kXn3Ta2RSTQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터세트 로드\n",
        "def get_dataset(batch_size, is_training = True):\n",
        "  split = 'train' if is_training else 'test'\n",
        "  dataset, info = tfds.load(name = 'mnist', split = split, with_info = True,\n",
        "                            as_supervised = True, try_gcs = True)\n",
        "  \n",
        "  # Normalize\n",
        "  def scale(image, label):\n",
        "    image = tf.casts(image, tf.float32)\n",
        "    image /= 255.0\n",
        "    return image, label\n",
        "\n",
        "  # 무한한 데이터셋의 장점 : 마지막 에포크에 들어가는 데이터의 수를 걱정할 필요가 없다\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "  dataset = dataset.batch(batch_size)\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "kR4BuyIcSAja"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "WygsO_iXTVcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TPU 관련 코드가 없죠\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer = 'adam',\n",
        "                loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "                metrics = ['sparse_categorical_accuracy'])\n",
        "  \n",
        "batch_size = 200\n",
        "steps_per_epoch = 60000 // batch_size\n",
        "validation_steps = 10000 // batch_size\n",
        "\n",
        "train_dataset = get_dataset(batch_size, is_training = True)\n",
        "test_dataset = get_dataset(batch_size, is_training = False)\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs = 5,\n",
        "          steps_per_epoch = steps_per_epoch,\n",
        "          validation_data = test_dataset,\n",
        "          validation_steps = validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhlXi0S-TSmj",
        "outputId": "08c79ac5-e281-4001-96cc-88ad1151391b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "300/300 [==============================] - 23s 46ms/step - loss: 1.2020 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.0820 - val_sparse_categorical_accuracy: 0.9753\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 11s 35ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.0764 - val_sparse_categorical_accuracy: 0.9790\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.0294 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0759 - val_sparse_categorical_accuracy: 0.9798\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0890 - val_sparse_categorical_accuracy: 0.9798\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.1153 - val_sparse_categorical_accuracy: 0.9759\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efeb7ebff50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TPU 성능 최대화하기\n",
        "- 인수 `steps_per_execution`을 `Model.compile`에 전달한다. "
      ],
      "metadata": {
        "id": "NXPg0I37T4Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer = 'adam',\n",
        "                steps_per_execution = 50, # 값은 2 ~ steps_per_epoch 사이로 전달한다.\n",
        "                loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "                metrics = ['sparse_categorical_accuracy'])\n",
        "  \n",
        "model.fit(train_dataset, epochs = 5,\n",
        "          steps_per_epoch = steps_per_epoch,\n",
        "          validation_data = test_dataset,\n",
        "          validation_steps = validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ldeoTYcT0yp",
        "outputId": "73d43488-c5ff-416b-82cf-2e878ac8e142"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "300/300 [==============================] - 17s 55ms/step - loss: 2.4735 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.0824 - val_sparse_categorical_accuracy: 0.9729\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.0728 - val_sparse_categorical_accuracy: 0.9772\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.0857 - val_sparse_categorical_accuracy: 0.9771\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 4s 15ms/step - loss: 0.0233 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0888 - val_sparse_categorical_accuracy: 0.9803\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.1093 - val_sparse_categorical_accuracy: 0.9762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efeb68ee310>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 예제에서는 70초 vs 33초의 성능 차이가 났음"
      ],
      "metadata": {
        "id": "JSWCyEs0UeCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사용자 지정 훈련 루프로 훈련"
      ],
      "metadata": {
        "id": "sj2hq_eZUi0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  training_loss = tf.keras.metrics.Mean('training_loss', dtype = tf.float32)\n",
        "  training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      'training_accuracy', dtype = tf.float32\n",
        "  )\n",
        "\n",
        "# 전달된 배치 크기 : 복제본당 배치 크기임(전역 배치 크기 아님)\n",
        "per_replica_batch_size = batch_size // strategy.num_replicas_in_sync # 각 TPU에 할당하는 batch 사이즈 계싼 & 분배\n",
        "\n",
        "# 함수가 지정된 데이터 세트를 배포\n",
        "train_dataset = strategy.experimental_distribute_datasets_from_function(\n",
        "    lambda _: get_dataset(per_replica_batch_size, is_training = True)\n",
        ")\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  def step_fn(inputs):\n",
        "    images, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(images, training = True)\n",
        "      loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "          labels, logits, from_logits = True\n",
        "      )\n",
        "      loss = tf.nn.compute_average_loss(loss, global_batch_size = batch_size)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "    training_accuracy.update_state(labels, logits)\n",
        "\n",
        "  strategy.run(step_fn, args = (next(iterator), ))"
      ],
      "metadata": {
        "id": "zVUaP0XSUQfB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 루프 실행\n",
        "steps_per_eval = 10000 // batch_size\n",
        "\n",
        "train_iterator = iter(train_dataset)\n",
        "for epoch in range(5):\n",
        "  print('Epoch : {} / 5'.format(epoch))\n",
        "\n",
        "  for step in range(steps_per_epoch):\n",
        "    train_step(train_iterator)\n",
        "\n",
        "  print(\"Current step : {}, training loss : {}, accuracy : {}%\".format(optimizer.iterations.numpy(),\n",
        "                                                                       round(float(training_loss.result()), 4),\n",
        "                                                                       round(float(training_accuracy.result()) * 100, 2)))\n",
        "  training_loss.reset_states()\n",
        "  training_accuracy.reset_states()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBHbJpmHVeeh",
        "outputId": "c5ea40e9-51c7-4ff2-ec25-7e78b521fdd1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 / 5\n",
            "Current step : 600, training loss : 1.4805, accuracy : 92.54%\n",
            "Epoch : 1 / 5\n",
            "Current step : 900, training loss : 0.0369, accuracy : 98.85%\n",
            "Epoch : 2 / 5\n",
            "Current step : 1200, training loss : 0.025, accuracy : 99.15%\n",
            "Epoch : 3 / 5\n",
            "Current step : 1500, training loss : 0.0188, accuracy : 99.34%\n",
            "Epoch : 4 / 5\n",
            "Current step : 1800, training loss : 0.0162, accuracy : 99.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `tf.function` 내부 여러 단계로 성능 향상\n",
        "- `tf.range` 내부 `tf.function`으로 `strategy.run` 호출을 래핑, AutoGraph는 이를 TPU 작업자의 `tf.while_loop`으로 변환한다."
      ],
      "metadata": {
        "id": "DGowzE4yW2Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_multiple_steps(iterator, steps):\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    images, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(images, training = True)\n",
        "      loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)\n",
        "      loss = tf.nn.compute_average_loss(loss, global_batch_size = batch_size)\n",
        "    grads = tape.gradient(loss,model.trainable_variables)\n",
        "    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "    training_accuracy.update_state(labels, logits)\n",
        "\n",
        "  # tf.range 내부의 tf.function으로 strategy.run 호출을 래핑\n",
        "  # AutoGraph는 이를 TPU 작업자의 tf.while_loop으로 변환한다.\n",
        "  for _ in tf.range(steps):\n",
        "    strategy.run(step_fn, args = (next(iterator), ))    \n",
        "    \n",
        "train_multiple_steps(train_iterator, tf.convert_to_tensor(steps_per_epoch))\n",
        "\n",
        "\n",
        "print(\"Current step : {}, Training Loss : {}, Accuracy : {} %\".format(\n",
        "    optimizer.iterations.numpy(),\n",
        "    round(float(training_loss.result()), 4),\n",
        "    round(float(training_accuracy.result()) * 100, 2))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZBV2-mGWPDx",
        "outputId": "3a023dd7-99ad-41f0-e641-6a30fb9c5c56"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current step : 2100, Training Loss : 0.0138, Accuracy : 99.54 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x0R4-R0qYAyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}