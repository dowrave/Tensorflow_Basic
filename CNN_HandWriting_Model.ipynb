{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_HandWriting_Model.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPxHF7Xb0bR0WfoUmouDmft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dowrave/Tensorflow_Basic/blob/main/CNN_HandWriting_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U_tJZdkw6mo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 데이터 전처리 : 채널 하나 더 만들고, 0~1 로 정규화\n",
        "train_images = train_images / 255.0\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28 ,1).astype('float32')\n",
        "\n",
        "test_images = test_images / 255.0\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28 ,1).astype('float32')\n",
        "\n",
        "# 데이터 배치 만들고 섞기\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(10000).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "\n",
        "class MyCNNModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyCNNModel, self).__init__()\n",
        "    self.conv1 = layers.Conv2D(32, 3, padding = 'same')\n",
        "    self.conv2 = layers.Conv2D(64, 3, padding = 'same')\n",
        "    self.conv3 = layers.Conv2D(128, 3, padding = 'same')\n",
        "    self.flatten = layers.Flatten()\n",
        "    self.batchnorm = layers.BatchNormalization()\n",
        "    self.lrelu = layers.LeakyReLU()\n",
        "    self.dropout = layers.Dropout(0.3)\n",
        "    self.d1 = layers.Dense(128, activation = 'relu')\n",
        "    self.d2 = layers.Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x) # 함수형으로 만들면 input_shape 설정 필요 없나??\n",
        "    # x = self.batchnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.conv2(x)\n",
        "    # x = self.batchnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.conv3(x)\n",
        "    # x = self.batchnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "model = MyCNNModel()\n",
        "# def myCNNModel():\n",
        "#   model = tf.keras.Sequential()\n",
        "#   model.add(layers.Conv2D(32, (5, 5), strides = (2,2), padding = 'same', input_shape = [28, 28, 1]))\n",
        "#   model.add(layers.LeakyReLU())\n",
        "#   model.add(layers.Dropout(0.3))\n",
        "\n",
        "#   model.add(layers.Conv2D(64, (5, 5), strides = (2,2), padding = 'same'))\n",
        "#   model.add(layers.LeakyReLU())\n",
        "#   model.add(layers.Dropout(0.3))\n",
        "\n",
        "#   model.add(layers.Conv2D(128, (5, 5), strides = (2,2), padding = 'same'))\n",
        "#   model.add(layers.LeakyReLU())\n",
        "#   model.add(layers.Dropout(0.3))\n",
        "\n",
        "#   model.add(layers.Flatten())\n",
        "#   model.add(layers.Dense(10))\n",
        "\n",
        "#   return model"
      ],
      "metadata": {
        "id": "5VF3q63cyQaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 & 손실 함수 정의\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# # 체크포인트 & 매니저 정의\n",
        "# ckpt = tf.train.Checkpoint(step = tf.Variable(1), optimizer = optimizer, net = model)\n",
        "# manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep = 5)"
      ],
      "metadata": {
        "id": "1E8TH6nB72v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 손실, 성능 측정 지표\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_acc')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_acc')\n"
      ],
      "metadata": {
        "id": "Ey4Ve7575SI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "@tf.function \n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training = True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_acc(labels, predictions)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "-eE78wfXynQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 정보 저장\n",
        "# def train_and_checkpoint(manager):\n",
        "#   ckpt.restore(manager.latest_checkpoint)\n",
        "#   if manager.latest_checkpoint == False:\n",
        "#     print(\"가져올 모델이 없음\")\n",
        "\n",
        "#   for images, labels in train_dataset:\n",
        "#     loss = train_step(images, labels)\n",
        "#     ckpt.step.assign_add(1)\n",
        "#     if int(ckpt.step) % 5 == 0:\n",
        "#       save_path = manager.save()\n",
        "#       print(f\"스텝 {int(ckpt.step)}의 값이 {save_path}에 저장됨.\")\n",
        "#       print('loss :{:1.2f}'.format(loss.numpy()))"
      ],
      "metadata": {
        "id": "rZBhB-Kk_bGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_and_checkpoint(manager)"
      ],
      "metadata": {
        "id": "Slvz5p2E_sQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images, \n",
        "                      training = False) # Dropout 같은 레이어는 자동으로 꺼짐\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_acc(labels, predictions)"
      ],
      "metadata": {
        "id": "wff-r1kSwtod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 훈련 과정\n",
        "\n",
        "def train(EPOCHS = 10):\n",
        "\n",
        "  for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss.reset_states()\n",
        "    train_acc.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_acc.reset_states()\n",
        "\n",
        "    for images, labels in train_dataset:\n",
        "      train_step(images, labels)\n",
        "\n",
        "    # 에포크에 대한 체크포인트를 작성하려면 여기에서 해야 함 - 체크포인트 저장\n",
        "    if epoch % 5 == 0 :\n",
        "      model.save_weights(f'save_epoch_{epoch}')\n",
        "      print(f'에포크 {epoch}의 모델 저장됨.')\n",
        "\n",
        "    for test_images, test_labels in test_dataset:\n",
        "      test_step(test_images, test_labels)\n",
        "\n",
        "    print(f'Epoch {epoch}', \n",
        "          f'Loss : {train_loss.result()}',\n",
        "          \"Accuracy : {:.2f}%\".format(train_acc.result() * 100),\n",
        "          f'Test Loss : {test_loss.result()}',\n",
        "          'Test Accuracy : {:.2f}'.format(test_acc.result() * 100)\n",
        "          )\n",
        "\n",
        "train(20)"
      ],
      "metadata": {
        "id": "sz2kdSRUxZBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트는 가중치만을 저장함 \n",
        "# 모델 자체로 저장하면 모델을 다시 정의할 필요 없이 이용할 수 있음 (h5)\n",
        "\n",
        "# 근데 SubClass Model을 이용한 경우는 h5로 저장이 불가능함 - 파이썬의 방법이기 떄문에 안전하게 Serialize할 수 없다는 듯\n",
        "# 텐서플로우에서는 TensorFlow SavedModel 포맷이나 save_weights를 쓸 것을 권고함\n",
        "model.save('my_model.tf') \n",
        "model.summary()\n",
        "# 모델 로드:\n",
        "# new_model = tf.keras.models.load_model('my_model.tf')\n",
        "# new_model.summary()"
      ],
      "metadata": {
        "id": "fY4k0K0pEezQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 암만 봐도 그냥 케라스 쓰는게 훨씬 편한..\n",
        "\n",
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wZfIDxcHxgh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LYrVjxbDQAuS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}